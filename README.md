
![Servidor de IA aberta no navegador](assets/servidor_ia.png)

![ExecuÃ§Ã£o do cÃ³digo em Python](assets/execucao_python.png)

![Resultado](assets/resultado.png)


# Pipeline de AnÃ¡lise de Sentimentos com LLM Local

Este projeto foi o desafio final da minha formaÃ§Ã£o em Python para IA. Ele consiste em um pipeline que processa resenhas de aplicativos em mÃºltiplos idiomas, realiza a traduÃ§Ã£o e classifica o sentimento de cada uma utilizando uma IA local.

## ğŸš€ Diferenciais TÃ©cnicos
- **InferÃªncia Local**: Configurado para rodar em hardware legado (MacBook Pro 2013) utilizando modelos quantizados.
- **Arquitetura Desacoplada**: Uso de servidor de inferÃªncia (Llamafile) separado da lÃ³gica de aplicaÃ§Ã£o (Python).
- **Processamento Estruturado**: Garantia de saÃ­da em formato JSON para integraÃ§Ã£o com sistemas de dados.

## ğŸ› ï¸ Tecnologias
- **Python 3.13**
- **OpenAI API Library** (para comunicaÃ§Ã£o com servidor local)
- **Llama 3.2 1B Instruct** (via Llamafile)
- **Venv** (Ambiente virtual para gestÃ£o de dependÃªncias)

## ğŸ“Š Como funciona
1. O script lÃª um arquivo `.txt` com resenhas brutas.
2. Cada resenha Ã© enviada para a LLM local com um prompt de sistema rigoroso.
3. A IA retorna um JSON com: usuÃ¡rio, texto original, traduÃ§Ã£o e sentimento.
4. O sistema consolida os dados e gera um relatÃ³rio de contagem de sentimentos.